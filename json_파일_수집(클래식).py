# -*- coding: utf-8 -*-
"""json_파일_수집(클래식).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WNuS5FoCZhUFc4OOiEeVb34N9l5uxRRf
"""

# 허깅페이스: AI 개발자들이 자신들의 모델이나 학습데이터등을 관리하는 생태계 (사이트)
# 데이터셋 라이브러리는 허깅페이스에서 요구하는 데이터포맷 으로 변환 및 관련 데이터 처리 함수 내장됨
!pip install datasets==2.21.0

import requests
import json
import pandas as pd
from datasets import Dataset
import huggingface_hub
import os

# prompt: 구글드라이브 마운트

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Colab Notebooks/fintech_edu_2025/중간고사LLM준비

# json.loads("./dataset/TL_multiple_choice.json")

url = "https://drive.google.com/uc?export=download&id=1JehPjKhyw9NlVdoKBv7ZtxZLqaEjN7H9"
response = requests.get(url)

filePath = "/content/drive/MyDrive/Colab Notebooks/fintech_edu_2025/중간고사LLM준비/dataset_클래식"

allDatas = []

filePath = "/content/drive/MyDrive/Colab Notebooks/fintech_edu_2025/중간고사LLM준비/dataset_클래식"

for i in range(92):
    file_name = f"PM_00{241 + i}_QNA_QUA.json"
    file_path = f"{filePath}/{file_name}"

    if os.path.exists(file_path):
        with open(file_path, encoding="UTF-8") as file:
            try:
                data = json.load(file)
                if isinstance(data, list):
                    allDatas.extend(data)  # 리스트일 경우 병합
                else:
                    allDatas.append(data)  # 딕셔너리일 경우 하나로 넣기
            except json.JSONDecodeError:
                print(f"JSON decode error: {file_path}")
    else:
        print(f"파일을 찾을 수 없습니다: {file_path}")

# 결과 출력
print(json.dumps(allDatas, ensure_ascii=False, indent="\t"))

allDatas

with open("/content/drive/MyDrive/Colab Notebooks/fintech_edu_2025/중간고사LLM준비/dataset_클래식/allDatas.json", "w", encoding="utf-8") as file:
    json.dump(allDatas, file, ensure_ascii=False, indent="\t")
    # 파일 경로를 'dataset_클래식/allDatas.json'으로 변경하여 디렉토리가 아닌 파일을 열도록 수정

url = "https://drive.google.com/uc?export=download&id=14fUay07Rqt34G2BYQ5SUj6E0BkdJAyVY"
delimeter = "\n보기\n"

response = requests.get(url)

original_data = json.loads(response.text)
print(original_data)

original_data

instructionList = []
inputList = []
outputList = []

# 원본데이터의 키 확인하기
original_data[0].keys()

len ( original_data[0]["explain"] )

explains = []
for i in range(50):
    explains.append(original_data[i]["explain"])

inAndOuts = []
for i in range(50):
    inAndOuts.append(original_data[i]["q&a"])

for i in range(0, len(explains)):
    inPut = explains[i]
    instruction = inAndOuts[i][0]["Questions"]
    outPut = inAndOuts[i][0]["Answer"]
    instructionList.append(instruction)
    inputList.append(inPut)
    outputList.append(outPut)

original_data[0]["explain"]

answerDf = pd.DataFrame( zip( instructionList, inputList, outputList),
                                    columns = ["INSTRUCTION","INPUT","OUTPUT"] )

answerDf

# # Dataset 형태로 변환
# dataset = Dataset.from_pandas(df)

# 허깅페이스 로그인 ( https://huggingface.co/ 회원가입 후 DATASET 하나 추가 이후 API 키 생성)
huggingface_hub.login()

# # 허깅페이스에 업로드 ( 본인의 데이터셋 생성한 주소를 적어야함)
# dataset.push_to_hub("hyokwan/common")

dataset = Dataset.from_pandas(answerDf)

huggingface_hub.login()

dataset.push_to_hub("jungseungin/classic_2")